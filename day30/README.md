Ex_day30_week6

Exercise 1 – Distribution Shift (NumPy)
When data comes from multiple distributions, the global mean and standard deviation can be misleading. A single summary statistic may not represent any real subgroup in the data.


Exercise 2 – Selection Bias (Pandas)
Filtering data (e.g., by city) can produce biased conclusions. Statistics computed on a selected subset may not generalize to the full population.


Exercise 3 – Simpson’s Paradox (Visualization)
An overall trend can reverse when data is split into subgroups due to a hidden confounding variable (such as age). Aggregate analysis alone can lead to incorrect interpretations.


Exercise 4 – Feature Scaling Effect in KNN
KNN relies on distance calculations, so features with larger scales dominate if data is not normalized. Proper scaling is essential to ensure all features contribute fairly.


Exercise 5 – Bias–Variance Tradeoff in KNN
Small values of k cause high variance and overfitting, while large values of k increase bias and lead to underfitting. Model performance depends on balancing bias and variance.
