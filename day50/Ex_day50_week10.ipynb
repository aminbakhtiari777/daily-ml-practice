{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n = 100\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"age\": np.random.randint(22, 50, n),\n",
        "    \"experience\": np.random.randint(0, 20, n),\n",
        "    \"salary\": np.random.randint(30000, 150000, n),\n",
        "    \"education_level\": np.random.choice([1, 2, 3], n)\n",
        "})\n",
        "df[\"career_stage\"]=None\n",
        "df.head()\n",
        "df[\"career_stage\"]=pd.cut(\n",
        "    df[\"experience\"],\n",
        "    bins=[-1, 1, 5, float(\"inf\")],\n",
        "     labels=[\"junior\", \"mid\", \"senior\"]\n",
        ")\n",
        "\n",
        "df=pd.get_dummies(df,columns=[\"career_stage\"])\n",
        "\n",
        "df_stage = pd.cut(\n",
        "    df[\"experience\"],\n",
        "    bins=[-1, 1, 5, float(\"inf\")],\n",
        "    labels=[\"junior\", \"mid\", \"senior\"]\n",
        ")\n",
        "\n",
        "salary_by_stage = df.groupby(df_stage)[\"salary\"].mean()\n",
        "print(salary_by_stage)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmdBj13P6acw",
        "outputId": "1456c22c-4058-4996-f652-24a93491fd28"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "experience\n",
            "junior     97206.166667\n",
            "mid       105284.235294\n",
            "senior     91155.619718\n",
            "Name: salary, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-706300646.py:31: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  salary_by_stage = df.groupby(df_stage)[\"salary\"].mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "np.random.seed(42)\n",
        "n = 200\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"age\": np.random.randint(22, 50, n),\n",
        "    \"experience\": np.random.randint(0, 20, n),\n",
        "    \"salary\": np.random.randint(30000, 150000, n),\n",
        "    \"education_level\": np.random.choice([1, 2, 3], n)\n",
        "})\n",
        "\n",
        "df[\"career_stage\"] = pd.cut(\n",
        "    df[\"experience\"],\n",
        "    bins=[-1, 1, 5, np.inf],\n",
        "    labels=[\"junior\", \"mid\", \"senior\"]\n",
        ")\n",
        "\n",
        "df = pd.get_dummies(df, columns=[\"career_stage\"], drop_first=True)\n",
        "\n",
        "features = [\n",
        "    \"age\",\n",
        "    \"experience\",\n",
        "    \"education_level\",\n",
        "    \"career_stage_mid\",\n",
        "    \"career_stage_senior\"\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df[\"salary\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "lin = LinearRegression()\n",
        "lin.fit(X_train, y_train)\n",
        "lin_pred = lin.predict(X_test)\n",
        "\n",
        "lin_r2 = r2_score(y_test, lin_pred)\n",
        "lin_mae = mean_absolute_error(y_test, lin_pred)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=300, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "rf_r2 = r2_score(y_test, rf_pred)\n",
        "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"LinearRegression\", \"RandomForest\"],\n",
        "    \"R2\": [lin_r2, rf_r2],\n",
        "    \"MAE\": [lin_mae, rf_mae]\n",
        "})\n",
        "\n",
        "print(results)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a_RGlD37sAG",
        "outputId": "c8331383-6ca0-4265-f028-f79e8a1d2b3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Model        R2           MAE\n",
            "0  LinearRegression -0.025314  31449.759167\n",
            "1      RandomForest -0.326954  34936.828154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "np.random.seed(42)\n",
        "n = 200\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"age\": np.random.randint(22, 50, n),\n",
        "    \"experience\": np.random.randint(0, 20, n),\n",
        "    \"salary\": np.random.randint(30000, 150000, n),\n",
        "    \"education_level\": np.random.choice([1, 2, 3], n)\n",
        "})\n",
        "\n",
        "df[\"career_stage\"] = pd.cut(\n",
        "    df[\"experience\"],\n",
        "    bins=[-1, 1, 5, np.inf],\n",
        "    labels=[\"junior\", \"mid\", \"senior\"]\n",
        ")\n",
        "\n",
        "df = pd.get_dummies(df, columns=[\"career_stage\"], drop_first=True)\n",
        "\n",
        "q75 = df[\"salary\"].quantile(0.75)\n",
        "df[\"elite\"] = (df[\"salary\"] >= q75).astype(int)\n",
        "\n",
        "features = [\"age\", \"experience\", \"education_level\", \"career_stage_mid\", \"career_stage_senior\"]\n",
        "X = df[features]\n",
        "y = df[\"elite\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "pos_rate = y.mean()\n",
        "print(\"Elite positive rate:\", pos_rate)\n",
        "\n",
        "log = LogisticRegression(max_iter=2000)\n",
        "log.fit(X_train, y_train)\n",
        "log_pred = log.predict(X_test)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=400, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "def metrics(y_true, y_pred, name):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\n\", name)\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"Precision:\", prec)\n",
        "    print(\"Recall:\", rec)\n",
        "    print(\"F1:\", f1)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    print(\"Report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
        "\n",
        "metrics(y_test, log_pred, \"LogisticRegression\")\n",
        "metrics(y_test, rf_pred, \"RandomForestClassifier\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT1gvV7m8Yoq",
        "outputId": "716df18a-2b42-42d3-8b93-9670f2baf320"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elite positive rate: 0.25\n",
            "\n",
            " LogisticRegression\n",
            "Accuracy: 0.75\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1: 0.0\n",
            "Confusion Matrix:\n",
            " [[30  0]\n",
            " [10  0]]\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86        30\n",
            "           1       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.75        40\n",
            "   macro avg       0.38      0.50      0.43        40\n",
            "weighted avg       0.56      0.75      0.64        40\n",
            "\n",
            "\n",
            " RandomForestClassifier\n",
            "Accuracy: 0.675\n",
            "Precision: 0.3333333333333333\n",
            "Recall: 0.3\n",
            "F1: 0.3157894736842105\n",
            "Confusion Matrix:\n",
            " [[24  6]\n",
            " [ 7  3]]\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.80      0.79        30\n",
            "           1       0.33      0.30      0.32        10\n",
            "\n",
            "    accuracy                           0.68        40\n",
            "   macro avg       0.55      0.55      0.55        40\n",
            "weighted avg       0.66      0.68      0.67        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "np.random.seed(42)\n",
        "n = 500\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"age\": np.random.randint(22, 50, n),\n",
        "    \"experience\": np.random.randint(0, 20, n),\n",
        "    \"salary\": np.random.randint(30000, 150000, n),\n",
        "    \"education_level\": np.random.choice([1, 2, 3], n)\n",
        "})\n",
        "\n",
        "df[\"career_stage\"] = pd.cut(\n",
        "    df[\"experience\"],\n",
        "    bins=[-1, 1, 5, np.inf],\n",
        "    labels=[\"junior\", \"mid\", \"senior\"]\n",
        ")\n",
        "df = pd.get_dummies(df, columns=[\"career_stage\"], drop_first=True)\n",
        "\n",
        "df[\"high_income\"] = (df[\"salary\"] > df[\"salary\"].median()).astype(int)\n",
        "\n",
        "features = [\"age\", \"experience\", \"education_level\", \"career_stage_mid\", \"career_stage_senior\"]\n",
        "X = df[features].values\n",
        "y = df[\"high_income\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", keras.metrics.Precision(name=\"precision\"), keras.metrics.Recall(name=\"recall\")]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(dict(zip(model.metrics_names, test_metrics)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opYMW1x98oPo",
        "outputId": "30ca4845-7ee6-4ea5-dbc7-f578e55dd48b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.4826 - loss: 0.7021 - precision: 0.4849 - recall: 0.9766 - val_accuracy: 0.5000 - val_loss: 0.6968 - val_precision: 0.4923 - val_recall: 0.8205\n",
            "Epoch 2/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5012 - loss: 0.6913 - precision: 0.4935 - recall: 0.7093 - val_accuracy: 0.4625 - val_loss: 0.6939 - val_precision: 0.4583 - val_recall: 0.5641\n",
            "Epoch 3/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5362 - loss: 0.6888 - precision: 0.5454 - recall: 0.5479 - val_accuracy: 0.5000 - val_loss: 0.6926 - val_precision: 0.4889 - val_recall: 0.5641\n",
            "Epoch 4/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5444 - loss: 0.6880 - precision: 0.5417 - recall: 0.5730 - val_accuracy: 0.5125 - val_loss: 0.6930 - val_precision: 0.5000 - val_recall: 0.5128\n",
            "Epoch 5/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5508 - loss: 0.6858 - precision: 0.5846 - recall: 0.5457 - val_accuracy: 0.4875 - val_loss: 0.6939 - val_precision: 0.4821 - val_recall: 0.6923\n",
            "Epoch 6/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5923 - loss: 0.6769 - precision: 0.5719 - recall: 0.6655 - val_accuracy: 0.5250 - val_loss: 0.6919 - val_precision: 0.5116 - val_recall: 0.5641\n",
            "Epoch 7/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5535 - loss: 0.6876 - precision: 0.5627 - recall: 0.5575 - val_accuracy: 0.5250 - val_loss: 0.6919 - val_precision: 0.5128 - val_recall: 0.5128\n",
            "Epoch 8/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5675 - loss: 0.6767 - precision: 0.6032 - recall: 0.5361 - val_accuracy: 0.5375 - val_loss: 0.6926 - val_precision: 0.5217 - val_recall: 0.6154\n",
            "Epoch 9/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5995 - loss: 0.6799 - precision: 0.6012 - recall: 0.6246 - val_accuracy: 0.5125 - val_loss: 0.6913 - val_precision: 0.5000 - val_recall: 0.5128\n",
            "Epoch 10/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5608 - loss: 0.6847 - precision: 0.5397 - recall: 0.4932 - val_accuracy: 0.5250 - val_loss: 0.6920 - val_precision: 0.5135 - val_recall: 0.4872\n",
            "Epoch 11/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5664 - loss: 0.6848 - precision: 0.5832 - recall: 0.5031 - val_accuracy: 0.5250 - val_loss: 0.6929 - val_precision: 0.5106 - val_recall: 0.6154\n",
            "Epoch 12/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5846 - loss: 0.6749 - precision: 0.5816 - recall: 0.6142 - val_accuracy: 0.5625 - val_loss: 0.6939 - val_precision: 0.5435 - val_recall: 0.6410\n",
            "Epoch 13/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6197 - loss: 0.6747 - precision: 0.6516 - recall: 0.6235 - val_accuracy: 0.5250 - val_loss: 0.6915 - val_precision: 0.5116 - val_recall: 0.5641\n",
            "Epoch 14/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6085 - loss: 0.6771 - precision: 0.6459 - recall: 0.5550 - val_accuracy: 0.5750 - val_loss: 0.6937 - val_precision: 0.5556 - val_recall: 0.6410\n",
            "Epoch 15/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5819 - loss: 0.6691 - precision: 0.6271 - recall: 0.5638 - val_accuracy: 0.5250 - val_loss: 0.6913 - val_precision: 0.5128 - val_recall: 0.5128\n",
            "Epoch 16/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5989 - loss: 0.6743 - precision: 0.6597 - recall: 0.5274 - val_accuracy: 0.5125 - val_loss: 0.6915 - val_precision: 0.5000 - val_recall: 0.5128\n",
            "Epoch 17/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5658 - loss: 0.6776 - precision: 0.6047 - recall: 0.4964 - val_accuracy: 0.5375 - val_loss: 0.6917 - val_precision: 0.5263 - val_recall: 0.5128\n",
            "Epoch 18/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6183 - loss: 0.6748 - precision: 0.6351 - recall: 0.4617 - val_accuracy: 0.5125 - val_loss: 0.6904 - val_precision: 0.5000 - val_recall: 0.3846\n",
            "Epoch 19/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5857 - loss: 0.6704 - precision: 0.5947 - recall: 0.4285 - val_accuracy: 0.5250 - val_loss: 0.6932 - val_precision: 0.5128 - val_recall: 0.5128\n",
            "Epoch 20/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5902 - loss: 0.6741 - precision: 0.6080 - recall: 0.5171 - val_accuracy: 0.5500 - val_loss: 0.6936 - val_precision: 0.5349 - val_recall: 0.5897\n",
            "Epoch 21/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5394 - loss: 0.6773 - precision: 0.5614 - recall: 0.5087 - val_accuracy: 0.5500 - val_loss: 0.6922 - val_precision: 0.5349 - val_recall: 0.5897\n",
            "Epoch 22/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6080 - loss: 0.6659 - precision: 0.6150 - recall: 0.6183 - val_accuracy: 0.5250 - val_loss: 0.6915 - val_precision: 0.5122 - val_recall: 0.5385\n",
            "Epoch 23/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5723 - loss: 0.6689 - precision: 0.6031 - recall: 0.4988 - val_accuracy: 0.5125 - val_loss: 0.6908 - val_precision: 0.5000 - val_recall: 0.5128\n",
            "Epoch 24/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6025 - loss: 0.6591 - precision: 0.6389 - recall: 0.5484 - val_accuracy: 0.5500 - val_loss: 0.6902 - val_precision: 0.5366 - val_recall: 0.5641\n",
            "Epoch 25/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6024 - loss: 0.6621 - precision: 0.6358 - recall: 0.5375 - val_accuracy: 0.5125 - val_loss: 0.6921 - val_precision: 0.5000 - val_recall: 0.5128\n",
            "Epoch 26/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6114 - loss: 0.6661 - precision: 0.6518 - recall: 0.5263 - val_accuracy: 0.5125 - val_loss: 0.6911 - val_precision: 0.5000 - val_recall: 0.4872\n",
            "Epoch 27/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5896 - loss: 0.6790 - precision: 0.5903 - recall: 0.5595 - val_accuracy: 0.5125 - val_loss: 0.6899 - val_precision: 0.5000 - val_recall: 0.5128\n",
            "Epoch 28/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5959 - loss: 0.6647 - precision: 0.6014 - recall: 0.5513 - val_accuracy: 0.5000 - val_loss: 0.6895 - val_precision: 0.4857 - val_recall: 0.4359\n",
            "Epoch 29/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5669 - loss: 0.6598 - precision: 0.6074 - recall: 0.4851 - val_accuracy: 0.5250 - val_loss: 0.6904 - val_precision: 0.5116 - val_recall: 0.5641\n",
            "Epoch 30/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5708 - loss: 0.6675 - precision: 0.5511 - recall: 0.5426 - val_accuracy: 0.5375 - val_loss: 0.6923 - val_precision: 0.5250 - val_recall: 0.5385\n",
            "{'loss': 0.7057812213897705, 'compile_metrics': 0.5600000023841858}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If Linear fails but RandomForest and Neural Network perform well, the data is clearly non-linear and contains meaningful feature interactions and likely threshold-based regimes. This means the target cannot be modeled as a simple linear combination of inputs, and higher-capacity models are capturing hidden structure that linear models miss. Strong performance from both RF and NN also suggests the signal-to-noise ratio is decent, and the main limitation was model bias rather than data quality. From an ML engineering perspective, this indicates a structured, interaction-heavy tabular problem where feature relationships matter more than model choice, and the next step should be understanding interactions and feature structure (e.g., via feature engineering or interpretability tools) rather than blindly increasing model complexity."
      ],
      "metadata": {
        "id": "NQFeq1MZ81Ro"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}